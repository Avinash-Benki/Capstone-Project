{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech-Recognizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Avinash-Benki/Capstone-Project/blob/master/Speech_Recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdcdJlgwbc2V",
        "colab_type": "text"
      },
      "source": [
        "# Speech Recognition Using Tensorflow "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjYN_i-1bkvB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "**Setting up Kaggle on Google Colab and Fetching Dataset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-BRnD6Dnj9h",
        "colab_type": "code",
        "outputId": "78b4a541-c535-46ed-c4d4-c915f6d80bc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.9.11)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMeK1QnbdGz_",
        "colab_type": "code",
        "outputId": "a2e0a151-3d51-4041-c4a8-f74215087903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCgBMLUNntp4",
        "colab_type": "code",
        "outputId": "224d5844-1a51-42f4-ea61-860ac29ece6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!mkdir .kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGPh3u3AoFE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "token = {\"username\":\"nivedithahn\",\"key\":\"b0918f0e714fa25a112ffdbab3d43b49\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UdYWme-oPPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAs9eHAyoU2F",
        "colab_type": "code",
        "outputId": "56344ae8-ec83-4086-8419-48d1b01732b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!kaggle config set -n path -v{/content}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "- path is now set to: {/content}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9l-S27WofBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l97DYjzZohxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxOKF9uXotZY",
        "colab_type": "code",
        "outputId": "b8b253cd-ea0a-41d4-a98f-722dc06f600e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!kaggle datasets list -s tensorflow-speech-recognition-challenge"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                         title                                               size  lastUpdated          downloadCount  \n",
            "----------------------------------------------------------  --------------------------------------------------  ----  -------------------  -------------  \n",
            "jbuchner/synthetic-speech-commands-dataset                  Synthetic Speech Commands Dataset                    2GB  2018-06-12 06:21:36            525  \n",
            "holzner/tensorflow-speech-recognition-vae-latent-variables  Tensorflow Speech recognition VAE latent variables  36MB  2018-01-12 22:09:44             63  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pwirrLbLfXS",
        "colab_type": "code",
        "outputId": "998686d0-1487-4f6e-8e34-4e9cbbec42aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/kaggle/speech'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_0wg9XZNIpu",
        "colab_type": "code",
        "outputId": "187ade27-4199-43a4-b056-1eeda52912b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!kaggle competitions download -c tensorflow-speech-recognition-challenge -p /content/gdrive/My\\ Dr\n",
        "ive/kaggle/speech"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading sample_submission.7z to /content/gdrive/My Drive/kaggle/speech\n",
            "  0% 0.00/501k [00:00<?, ?B/s]\n",
            "100% 501k/501k [00:00<00:00, 35.2MB/s]\n",
            "Downloading train.7z to /content/gdrive/My Drive/kaggle/speech\n",
            "100% 1.04G/1.04G [00:10<00:00, 91.1MB/s]\n",
            "100% 1.04G/1.04G [00:10<00:00, 108MB/s] \n",
            "Downloading test.7z to /content/gdrive/My Drive/kaggle/speech\n",
            "100% 2.46G/2.46G [01:15<00:00, 47.8MB/s]\n",
            "\n",
            "Downloading link_to_gcp_credits_form.txt to /content/gdrive/My Drive/kaggle/speech\n",
            "100% 50.0/50.0 [00:01<00:00, 32.5B/s]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sod8m2SpphkR",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-TE8HT40pO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/kaggle/speech')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUnDwb892A7O",
        "colab_type": "code",
        "outputId": "1e89c498-2eea-4a96-9003-f10706b9287b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "link_to_gcp_credits_form.txt  test     train\n",
            "sample_submission.csv\t      test.7z  train.7z\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK1YfIqqQpVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir train  #create a directory named train/\n",
        "!mkdir test  #create a directory named test/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TolG76uQsEm",
        "colab_type": "code",
        "outputId": "986ab08d-edd1-42db-d77f-17a372e8a6c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "link_to_gcp_credits_form.txt  test     train\n",
            "sample_submission.7z\t      test.7z  train.7z\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxsaOY3mQ53b",
        "colab_type": "code",
        "outputId": "2ca8d53b-0618-4cd4-8381-04611901bbb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!apt-get install p7zip-full"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "p7zip-full is already the newest version (16.02+dfsg-6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3GB-oWjT8Iz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!p7zip -d train.7z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irTgzNuAXIWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!p7zip -d test.7z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHZIXnZPdShm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/kaggle/speech')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qjKyUGIeRIh",
        "colab_type": "code",
        "outputId": "f1efeead-4251-4df0-f5e0-39a3cb69f4de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "!p7zip -d sample_submission.7z"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 512684 bytes (501 KiB)\n",
            "\n",
            "Extracting archive: sample_submission.7z\n",
            "--\n",
            "Path = sample_submission.7z\n",
            "Type = 7z\n",
            "Physical Size = 512684\n",
            "Headers Size = 146\n",
            "Method = LZMA2:6m\n",
            "Solid = -\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\bEverything is Ok\n",
            "\n",
            "Size:       4280538\n",
            "Compressed: 512684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWcYriMzbTDl",
        "colab_type": "text"
      },
      "source": [
        "# Begining of the Speech Recognition Part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPTPWxwpbSO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds9nnU0pusZJ",
        "colab_type": "code",
        "outputId": "0ee43d47-b594-48c1-db9a-f4bd286e836f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "dir_path = '/content/gdrive/My Drive/kaggle/speech'\n",
        "\n",
        "#Getting the list of testing file names\n",
        "\n",
        "testing_path_dir = os.path.join(dir_path,'train')\n",
        "testing_path = os.path.join(testing_path_dir, 'testing_list.txt')\n",
        "testing_list = np.genfromtxt(testing_path, dtype=None, encoding=None)\n",
        "print(\"Retrieved testing_list from \"+ testing_path+ \". Size is \" + str(testing_list.shape)+\".\")\n",
        "\n",
        "#Getting the list of Validation file names\n",
        "\n",
        "validation_path_dir = os.path.join(dir_path,'train')\n",
        "validation_path =  os.path.join(testing_path_dir, 'validation_list.txt')\n",
        "validation_list = np.genfromtxt(validation_path, dtype=None, encoding=None)\n",
        "print(\"Retrieved validation list from \"+ validation_path + \". Size is \" + str(validation_list.shape)+\".\")\n",
        "\n",
        "#Generate training file name list \n",
        "\n",
        "training_path_dir = os.path.join(dir_path,'train/audio')\n",
        "all_files_list = np.array(glob.glob(os.path.join(training_path_dir, '*', '*.wav')))\n",
        "np.savetxt('train/all_files_list.txt',all_files_list, encoding=None, fmt='%.100s')\n",
        "audio_path_length = len(training_path_dir)+1\n",
        "\n",
        "#Training list creation by removing file names common to testing or validation list\n",
        "training_list = np.array([])\n",
        "for index, value in np.ndenumerate(all_files_list):\n",
        "    value = value[audio_path_length:]\n",
        "    all_files_list[index] = value\n",
        "    if np.isin([value],testing_list)==False and np.isin([value],validation_list)==False:\n",
        "        training_list = np.append(training_list, all_files_list[index])\n",
        "print(str(training_list.shape) + \" is the shape of the training_list.\")\n",
        "np.savetxt('train/training_list.txt',training_list, encoding=None, fmt='%.100s')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Retrieved testing_list from /content/gdrive/My Drive/kaggle/speech/train/testing_list.txt. Size is (6835,).\n",
            "Retrieved validation list from /content/gdrive/My Drive/kaggle/speech/train/validation_list.txt. Size is (6798,).\n",
            "(35328,) is the shape of the training_list.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JleDLSLFI4dB",
        "colab_type": "text"
      },
      "source": [
        "## Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eOW9ovIJUO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Math\n",
        "from scipy.io import wavfile\n",
        "import librosa\n",
        "from scipy import signal\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import IPython.display as ipd\n",
        "import librosa.display\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUrtqwYG4Edv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " train_audio_path = '/content/gdrive/My Drive/kaggle/speech/train/audio/'+filename\n",
        " y, sr  = librosa.load(train_audio_path,sr=16000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGAyZA_xLdSk",
        "colab_type": "text"
      },
      "source": [
        "Calculating the mel-spectrum for the sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYbMdt5PLqId",
        "colab_type": "code",
        "outputId": "85538655-961d-4e76-f581-0b392a30635a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "# From this tutorial\n",
        "# https://github.com/librosa/librosa/blob/master/examples/LibROSA%20demo.ipynb\n",
        "S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128, n_fft=512, hop_length=200)\n",
        "\n",
        "# Convert to log scale (dB). We'll use the peak power (max) as reference.\n",
        "log_S = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "mfcc = librosa.feature.mfcc(S=log_S, n_mfcc=13)\n",
        "print(mfcc.shape)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel')\n",
        "plt.title('Mel power spectrogram ')\n",
        "plt.colorbar(format='%+02.0f dB')\n",
        "plt.tight_layout()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7ccc84a8f749>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Convert to log scale (dB). We'll use the peak power (max) as reference.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlog_S\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3YvcWcAU4HU",
        "colab_type": "code",
        "outputId": "3c7852cc-3f2b-4246-f0df-c7aac5766511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        }
      },
      "source": [
        "# Next, we'll extract the top 13 Mel-frequency cepstral coefficients (MFCCs)\n",
        "mfcc = librosa.feature.mfcc(S=log_S, n_mfcc=12)\n",
        "\n",
        "# Let's pad on the first and second deltas while we're at it\n",
        "delta_mfcc  = librosa.feature.delta(mfcc)\n",
        "delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
        "\n",
        "# How do they look?  We'll show each in its own subplot\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(3,1,1)\n",
        "librosa.display.specshow(mfcc)\n",
        "plt.ylabel('MFCC')\n",
        "plt.colorbar()\n",
        "\n",
        "plt.subplot(3,1,2)\n",
        "librosa.display.specshow(delta_mfcc)\n",
        "plt.ylabel('MFCC-$\\Delta$')\n",
        "plt.colorbar()\n",
        "\n",
        "plt.subplot(3,1,3)\n",
        "librosa.display.specshow(delta2_mfcc, sr=sr, x_axis='time')\n",
        "plt.ylabel('MFCC-$\\Delta^2$')\n",
        "plt.colorbar()\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# For future use, we'll stack these together into one matrix\n",
        "M = np.vstack([mfcc, delta_mfcc, delta2_mfcc])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwUAAAGoCAYAAAAXeElgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSR1nUSBJkiR1nEWBJEmS1HH/P/uEmNIKjnzqAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x432 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yg6oDGOPWsuq",
        "colab_type": "text"
      },
      "source": [
        "Following is the function that will calculate the mfcc coefficients "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0z5r0hcWyXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mfcc_conversion(filename, sample_rate = 16000):\n",
        "  train_audio_path = '/content/gdrive/My Drive/kaggle/speech/train/audio/'+filename\n",
        "  y, sr  = librosa.load(train_audio_path,sr=16000)\n",
        "  \n",
        "  S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128, n_fft=512, hop_length=400)\n",
        "\n",
        "  # Convert to log scale (dB). We'll use the peak power (max) as reference.\n",
        "  log_S = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "  mfcc = librosa.feature.mfcc(S=log_S, n_mfcc=13)\n",
        "  print(S.shape)\n",
        "  return mfcc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OyMVeJQgXjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.io import wavfile\n",
        "from scipy.fftpack import dct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIZi9BBLgwOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGyK9NEWg0iB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/kaggle/speech/data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV5ztY2HzYKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW50AEids7W1",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9a1IF7Vliom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_validation = np.empty((0,128, 81), float)\n",
        "\n",
        "\n",
        "# decode validation_list\n",
        "for i in range(0, validation_list.shape[0]):\n",
        "    mfccs = mfcc_conversion(validation_list[i])\n",
        "    mfccs = np.expand_dims(mfccs, axis=0)\n",
        "    x_validation = np.vstack((x_validation, mfccs))\n",
        "np.save('/content/gdrive/My Drive/kaggle/speech/data/x_validation', x_validation)    \n",
        "print(\"Validation list audio decode complete.\")\n",
        "\n",
        "x_testing = np.empty((0,128,81), float)\n",
        "# decode testing_list\n",
        "for i in range(0, testing_list.shape[0]):\n",
        "    mfccs = mfcc_conversion(testing_list[i])\n",
        "    mfccs = np.expand_dims(mfccs, axis=0)\n",
        "    x_testing = np.vstack((x_testing, mfccs))\n",
        "np.save('/content/gdrive/My Drive/kaggle/speech/data/x_testing', x_testing)\n",
        "print(\"Testing list audio decode complete.\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73W6qxE61N3B",
        "colab_type": "code",
        "outputId": "aeed5734-7e7b-4bfd-fc19-7cb198e833a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(x_training.shape)\n",
        "print(x_training[1][1][1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35328, 128, 41)\n",
            "5.173680977183568e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAXsxw8YnlrE",
        "colab_type": "code",
        "outputId": "63487ad9-840c-4ca6-fb34-4162d86d87c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CQUzMHrmfkI",
        "colab_type": "code",
        "outputId": "05562a0b-1c1c-4d7c-e505-1999900917bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "# audio targets are determined by the name of their parent folder\n",
        "def audio_categorizer(x_arr):\n",
        "    y_arr=np.array([])\n",
        "    for index, value in np.ndenumerate(x_arr):\n",
        "        keyword = os.path.dirname(value)\n",
        "        if keyword == \"yes\":\n",
        "            y_arr = np.append(y_arr,1)\n",
        "        elif keyword == \"no\":\n",
        "            y_arr = np.append(y_arr,2)\n",
        "        elif keyword == \"up\":\n",
        "            y_arr = np.append(y_arr,3)\n",
        "        elif keyword == \"down\":\n",
        "            y_arr = np.append(y_arr,4)\n",
        "        elif keyword == \"left\":\n",
        "            y_arr = np.append(y_arr,5)\n",
        "        elif keyword == \"right\":\n",
        "            y_arr = np.append(y_arr,6)\n",
        "        elif keyword == \"on\":\n",
        "            y_arr = np.append(y_arr,7)\n",
        "        elif keyword == \"off\":\n",
        "            y_arr = np.append(y_arr,8)\n",
        "        elif keyword == \"stop\":\n",
        "            y_arr = np.append(y_arr,9)\n",
        "        elif keyword == \"go\":\n",
        "            y_arr = np.append(y_arr,10)\n",
        "        else:\n",
        "            y_arr = np.append(y_arr,0)\n",
        "    return y_arr \n",
        "\n",
        "# categorize training labels\n",
        "y_training = audio_categorizer(training_list)\n",
        "y_validation = audio_categorizer(validation_list)\n",
        "y_testing = audio_categorizer(testing_list)\n",
        "\n",
        "# applying a one-hot encoding scheme\n",
        "y_training = np_utils.to_categorical(y_training, 11)\n",
        "y_validation = np_utils.to_categorical(y_validation, 11)\n",
        "y_testing = np_utils.to_categorical(y_testing, 11)\n",
        "\n",
        "# add dimension for network processing\n",
        "y_training = np.expand_dims(y_training, axis=1)\n",
        "y_validation = np.expand_dims(y_validation, axis=1)\n",
        "y_testing = np.expand_dims(y_testing, axis=1)\n",
        "\n",
        "print('The shape of training targets is '+str(y_training.shape))\n",
        "print('The shape of validation targets is '+str(y_validation.shape))\n",
        "print('The shape of testing targets is '+str(y_testing.shape))\n",
        "\n",
        "# save MFCC datasets for future use\n",
        "np.save('/content/gdrive/My Drive/kaggle/speech/data/y_training', y_training)\n",
        "np.save('/content/gdrive/My Drive/kaggle/speech/data/y_validation', y_validation)\n",
        "np.save('/content/gdrive/My Drive/kaggle/speech/data/y_testing', y_testing)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of training targets is (35328, 1, 11)\n",
            "The shape of validation targets is (6798, 1, 11)\n",
            "The shape of testing targets is (6835, 1, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOpBp-8i5Psw",
        "colab_type": "code",
        "outputId": "6326362a-18d1-4242-c684-7b2451bb2cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "print('The shape of training targets is '+str(x_training.shape))\n",
        "print('The shape of validation targets is '+str(x_validation.shape))\n",
        "print('The shape of testing targets is '+str(x_testing.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of training targets is (35328, 128, 41)\n",
            "The shape of validation targets is (6798, 128, 41)\n",
            "The shape of testing targets is (6835, 128, 41)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zX925nGpO4b",
        "colab_type": "text"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYNJU7RypUZ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "7b90352f-5011-45c3-e66a-19b604cdc9ac"
      },
      "source": [
        "from keras.models import Model, Sequential, load_model\n",
        "\n",
        "from keras.layers import Input, Activation, Concatenate, Permute,AveragePooling1D, Reshape, Flatten, Lambda, Dot, Softmax\n",
        "from keras.layers import Add, Dropout, BatchNormalization,Conv1D, MaxPooling1D, Conv2D, Reshape, MaxPooling2D, Dense, CuDNNLSTM, Bidirectional,ZeroPadding1D,LSTM\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "from kapre.time_frequency import Melspectrogram, Spectrogram\n",
        "from kapre.utils import Normalization2D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers.convolutional_recurrent import ConvLSTM2D"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv3hZk37ozpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_1_architecture(dropout_rate=0):\n",
        "    x_in = inputs = Input((128,41,1))\n",
        "    x = Normalization2D(int_axis=0)(x_in)\n",
        "    #note that Melspectrogram puts the sequence in shape (batch_size, melDim, timeSteps, 1)\n",
        "    #we would rather have it the other way around for LSTMs\n",
        "\n",
        "    x = Permute((2,1,3)) (x)\n",
        "    #x = Reshape((94,80)) (x) #this is strange - but now we have (batch_size, sequence, vec_dim)\n",
        "\n",
        "    c1 = Conv2D(20, (5,1) , activation='relu', padding='same') (x)\n",
        "    c1 = BatchNormalization() (c1)\n",
        "    p1 = MaxPooling2D((2, 1)) (c1)\n",
        "    p1 = Dropout(0.03) (p1)\n",
        "\n",
        "    c2 = Conv2D(40, (3,3) , activation='relu', padding='same') (p1)\n",
        "    c2 = BatchNormalization() (c2)\n",
        "    p2 = MaxPooling2D((2, 2)) (c2)\n",
        "    p2 = Dropout(0.01) (p2)\n",
        "\n",
        "    c3 = Conv2D(80, (3,3) , activation='relu', padding='same') (p2)\n",
        "    c3 = BatchNormalization() (c3)\n",
        "    p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "    p3 = Flatten()(p3)\n",
        "    p3 = Dense(64, activation = 'relu')(p3)\n",
        "  \n",
        "    p3 = Dense(32, activation = 'relu')(p3)\n",
        "    \n",
        "    output = Dense(11, activation = 'sigmoid')(p3)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[output], name='ConvSpeechModel')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzI8TGc5DeAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def AttRNNSpeechModel(nCategories=11, samplingrate = 16000, inputLength = 16000, rnn_func = CuDNNLSTM):\n",
        "    x_in = inputs = Input((128,41,1))\n",
        "    x = Normalization2D(int_axis=0)(x_in)\n",
        "    #note that Melspectrogram puts the sequence in shape (batch_size, melDim, timeSteps, 1)\n",
        "    #we would rather have it the other way around for LSTMs\n",
        "    x = Conv2D(10, (5,1) , activation='relu', padding='same') (x)\n",
        "    x = BatchNormalization() (x)\n",
        "    x = Conv2D(1, (5,1) , activation='relu', padding='same') (x)\n",
        "    x = BatchNormalization() (x)\n",
        "\n",
        "    #x = Reshape((125, 80)) (x)\n",
        "    x = Lambda(lambda q: K.squeeze(q, -1), name='squeeze_last_dim') (x) #keras.backend.squeeze(x, axis)\n",
        "\n",
        "    x = Bidirectional(rnn_func(64, return_sequences = True)) (x) # [b_s, seq_len, vec_dim]\n",
        "    x = Bidirectional(rnn_func(64, return_sequences = True)) (x) # [b_s, seq_len, vec_dim]\n",
        "\n",
        "    xFirst = Lambda(lambda q: q[:,64]) (x) #[b_s, vec_dim]\n",
        "    query = Dense(128) (xFirst)\n",
        "\n",
        "    #dot product attention\n",
        "    attScores = Dot(axes=[1,2])([query, x]) \n",
        "    attScores = Softmax(name='attSoftmax')(attScores) #[b_s, seq_len]\n",
        "\n",
        "    #rescale sequence\n",
        "    attVector = Dot(axes=[1,1])([attScores, x]) #[b_s, vec_dim]\n",
        "\n",
        "    x = Dense(64, activation = 'relu')(attVector)\n",
        "    x = Dense(32)(x)\n",
        "\n",
        "    output = Dense(nCategories, activation = 'softmax', name='output')(x)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[output])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGBfEwqNDqE1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "outputId": "fd8a24e5-74c5-4aab-b57c-21c55ec31386"
      },
      "source": [
        "print(\"AttRNNSpeechModel Network Summary\")\n",
        "model = AttRNNSpeechModel()\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AttRNNSpeechModel Network Summary\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 128, 41, 1)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "normalization2d_4 (Normalizatio (None, 128, 41, 1)   0           input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 128, 41, 10)  60          normalization2d_4[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 128, 41, 10)  40          conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 128, 41, 1)   51          batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 128, 41, 1)   4           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "squeeze_last_dim (Lambda)       (None, 128, 41)      0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 128, 128)     54784       squeeze_last_dim[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 128, 128)     99328       bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 128)          0           bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 128)          16512       lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 128)          0           dense_7[0][0]                    \n",
            "                                                                 bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "attSoftmax (Softmax)            (None, 128)          0           dot_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dot_2 (Dot)                     (None, 128)          0           attSoftmax[0][0]                 \n",
            "                                                                 bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 64)           8256        dot_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 32)           2080        dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 11)           363         dense_9[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 181,478\n",
            "Trainable params: 181,456\n",
            "Non-trainable params: 22\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm7Uo-QTpbS8",
        "colab_type": "code",
        "outputId": "c8da12d5-e1a7-41fa-e4a1-6f5c003346b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = model_1_architecture()\n",
        "print(\"Model 1 Network Summary\")\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model 1 Network Summary\n",
            "Model: \"ConvSpeechModel\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 128, 41, 1)        0         \n",
            "_________________________________________________________________\n",
            "normalization2d_1 (Normaliza (None, 128, 41, 1)        0         \n",
            "_________________________________________________________________\n",
            "permute_1 (Permute)          (None, 41, 128, 1)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 41, 128, 20)       120       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 41, 128, 20)       80        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 20, 128, 20)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20, 128, 20)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 20, 128, 40)       7240      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 20, 128, 40)       160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 10, 64, 40)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 10, 64, 40)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 10, 64, 80)        28880     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 10, 64, 80)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 32, 80)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                819264    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 11)                363       \n",
            "=================================================================\n",
            "Total params: 858,507\n",
            "Trainable params: 858,227\n",
            "Non-trainable params: 280\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFuRYOapkWjw",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drk-HBAe4ztZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_1_train(x_training, y_training,x_validation,y_validation, dropout_rate,\n",
        "                  learning_rate, relu_alpha, batch_size=1000, epochs=60):\n",
        "    model = model_1_architecture(dropout_rate)\n",
        "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    dir_path = os.path.join('/content/gdrive/My Drive/kaggle/speech','model')\n",
        "    file_name = 'model1_dr'+'.hdf5'\n",
        "    checkpoint_file = os.path.join(dir_path, file_name)\n",
        "    checkpointer = ModelCheckpoint(filepath=checkpoint_file, verbose=1, save_best_only=True)\n",
        "    early_stopper = EarlyStopping(patience=10, verbose=1)\n",
        "    hist = model.fit(x_training, y_training, batch_size=batch_size, epochs=epochs,\n",
        "                  validation_data=(x_validation, y_validation), callbacks=[checkpointer, early_stopper], \n",
        "                  verbose=2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b58Pf5PJqWhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def AttRNNSpeechModel_train(x_training, y_training,x_validation,y_validation, dropout_rate,\n",
        "                  learning_rate, relu_alpha, batch_size=1000, epochs=60):\n",
        "    model = AttRNNSpeechModel(11, 16000, 16000, CuDNNLSTM)\n",
        "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    dir_path = os.path.join('/content/gdrive/My Drive/kaggle/speech','model')\n",
        "    file_name = 'model3_dr'+'.hdf5'\n",
        "    checkpoint_file = os.path.join(dir_path, file_name)\n",
        "    checkpointer = ModelCheckpoint(filepath=checkpoint_file, verbose=1, save_best_only=True)\n",
        "    early_stopper = EarlyStopping(patience=10, verbose=1)\n",
        "    hist = model.fit(x_training, y_training, batch_size=batch_size, epochs=epochs,\n",
        "                  validation_data=(x_validation, y_validation), callbacks=[checkpointer, early_stopper], \n",
        "                  verbose=2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_TIl8jj45Yk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0799cc9a-7c03-4174-de38-1a98580cc5c1"
      },
      "source": [
        "# load training and validation data into memory\n",
        "x_training = np.load('/content/gdrive/My Drive/kaggle/speech/data/x_training.npy')\n",
        "x_validation = np.load('/content/gdrive/My Drive/kaggle/speech/data/x_validation.npy')\n",
        "\n",
        "y_training = np.load('/content/gdrive/My Drive/kaggle/speech/data/y_training.npy')\n",
        "y_validation = np.load('/content/gdrive/My Drive/kaggle/speech/data/y_validation.npy')\n",
        "\n",
        "xt=np.expand_dims(x_training, axis=3)\n",
        "print(xt.shape)\n",
        "\n",
        "yt=y_training.reshape(y_training.shape[0],y_training.shape[1]*y_training.shape[2])\n",
        "print(yt.shape)\n",
        "xv=np.expand_dims(x_validation, axis=3)\n",
        "yv=y_validation.reshape(y_validation.shape[0],y_validation.shape[1]*y_validation.shape[2])\n",
        "print(xv.shape)\n",
        "print(yv.shape)\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 1000\n",
        "epochs = 60\n",
        "\n",
        "model = model_1_train(xt, yt,xv,yv, dropout_rate=0.25,learning_rate=0.01,relu_alpha=0.00, batch_size=batch_size, epochs=epochs)\n",
        "                                         \n",
        "                                        "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35328, 128, 41, 1)\n",
            "(35328, 11)\n",
            "(6798, 128, 41, 1)\n",
            "(6798, 11)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 35328 samples, validate on 6798 samples\n",
            "Epoch 1/60\n",
            " - 28s - loss: 3.1362 - acc: 0.5978 - val_loss: 3.2060 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.20601, saving model to /content/gdrive/My Drive/kaggle/speech/model/model1_dr.hdf5\n",
            "Epoch 2/60\n",
            " - 21s - loss: 2.8130 - acc: 0.6334 - val_loss: 3.6651 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 3.20601\n",
            "Epoch 3/60\n",
            " - 21s - loss: 2.3115 - acc: 0.6009 - val_loss: 2.1554 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00003: val_loss improved from 3.20601 to 2.15543, saving model to /content/gdrive/My Drive/kaggle/speech/model/model1_dr.hdf5\n",
            "Epoch 4/60\n",
            " - 21s - loss: 1.4036 - acc: 0.6334 - val_loss: 2.2508 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 2.15543\n",
            "Epoch 5/60\n",
            " - 21s - loss: 1.4237 - acc: 0.6334 - val_loss: 2.7701 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 2.15543\n",
            "Epoch 6/60\n",
            " - 21s - loss: 1.3908 - acc: 0.6334 - val_loss: 2.6245 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 2.15543\n",
            "Epoch 7/60\n",
            " - 21s - loss: 1.3876 - acc: 0.6334 - val_loss: 2.5893 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 2.15543\n",
            "Epoch 8/60\n",
            " - 21s - loss: 1.3848 - acc: 0.6334 - val_loss: 2.9131 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 2.15543\n",
            "Epoch 9/60\n",
            " - 21s - loss: 1.3828 - acc: 0.6334 - val_loss: 2.9051 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 2.15543\n",
            "Epoch 10/60\n",
            " - 21s - loss: 1.3805 - acc: 0.6334 - val_loss: 2.8287 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 2.15543\n",
            "Epoch 11/60\n",
            " - 21s - loss: 1.3793 - acc: 0.6334 - val_loss: 2.8885 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 2.15543\n",
            "Epoch 12/60\n",
            " - 21s - loss: 1.3788 - acc: 0.6334 - val_loss: 2.8922 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 2.15543\n",
            "Epoch 13/60\n",
            " - 21s - loss: 1.3786 - acc: 0.6334 - val_loss: 2.9094 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 2.15543\n",
            "Epoch 00013: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNd6GHWnETZi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "outputId": "95e45074-7d48-49b9-9a15-7001105cf6bf"
      },
      "source": [
        "model = AttRNNSpeechModel_train(xt, yt,xv,yv, dropout_rate=0.25,learning_rate=0.01,relu_alpha=0.00, batch_size=batch_size, epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 35328 samples, validate on 6798 samples\n",
            "Epoch 1/60\n",
            " - 17s - loss: 1.4701 - acc: 0.6153 - val_loss: 1.8994 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.89938, saving model to /content/gdrive/My Drive/kaggle/speech/model/model3_dr.hdf5\n",
            "Epoch 2/60\n",
            " - 14s - loss: 1.3816 - acc: 0.6334 - val_loss: 1.9390 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1.89938\n",
            "Epoch 3/60\n",
            " - 14s - loss: 1.3786 - acc: 0.6334 - val_loss: 2.0670 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.89938\n",
            "Epoch 4/60\n",
            " - 14s - loss: 1.3781 - acc: 0.6334 - val_loss: 2.5206 - val_acc: 0.0388\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.89938\n",
            "Epoch 5/60\n",
            " - 14s - loss: 1.3764 - acc: 0.6334 - val_loss: 2.1628 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.89938\n",
            "Epoch 6/60\n",
            " - 14s - loss: 1.3745 - acc: 0.6334 - val_loss: 2.5056 - val_acc: 0.0388\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.89938\n",
            "Epoch 7/60\n",
            " - 14s - loss: 1.3750 - acc: 0.6334 - val_loss: 2.1799 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.89938\n",
            "Epoch 8/60\n",
            " - 14s - loss: 1.3740 - acc: 0.6334 - val_loss: 2.2822 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.89938\n",
            "Epoch 9/60\n",
            " - 14s - loss: 1.3747 - acc: 0.6334 - val_loss: 2.3459 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.89938\n",
            "Epoch 10/60\n",
            " - 14s - loss: 1.3742 - acc: 0.6334 - val_loss: 2.4356 - val_acc: 0.6209\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.89938\n",
            "Epoch 11/60\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}